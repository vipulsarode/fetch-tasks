{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Task Learning Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vipulsarode/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/Users/vipulsarode/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a SentenceTransformer_V2 Class which inherits torch.nn.Module and uses BERT model and takes sentences as input to give fixed-size shared embeddings\n",
    "# Then it passes the shared embeddings to the classification task head and sentiment task head for multi-tasking purposes.\n",
    "\n",
    "class SentenceTransformer_V2(nn.Module):\n",
    "    def __init__(self, model_name='bert-base-uncased'):\n",
    "        super().__init__()\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_name) # Importing BertTokenizer to tokenize sentences\n",
    "        self.bert = BertModel.from_pretrained(model_name) # Importing BertModel to extract contextualized embeddings from sentences\n",
    "    \n",
    "        #Defining Sentences Classification Head\n",
    "        self.text_classification = nn.Sequential(\n",
    "            nn.Linear(768,128),  # First layer of the classification head\n",
    "            nn.ReLU(), # Assigning an activation function between two layers\n",
    "            nn.Linear(128,5) # Final layer of classification head with output of shape 5 to classify 5 classes, for example - happy, sad, angry, fear, disgust\n",
    "        )\n",
    "\n",
    "        #Defining Sentiment Classification Head\n",
    "        self.sentiment = nn.Sequential(\n",
    "            nn.Linear(768,128), # First layer of the sentiment head\n",
    "            nn.ReLU(), # Assigning an activation function between two layers\n",
    "            nn.Linear(128,3) #FInal layer of sentiment head wiith output of shape 2 for positive, negative and neutral sentiment classification\n",
    "        )\n",
    "\n",
    "    def forward(self, sentences):\n",
    "        tokens = self.tokenizer(sentences, padding = True, truncation = True, return_tensors = 'pt') # Tokenizing all the sentences\n",
    "        outputs = self.bert(input_ids=tokens['input_ids'], token_type_ids=tokens['token_type_ids'], attention_mask=tokens['attention_mask']) # Using BertModel to extract shared embeddings\n",
    "        embeddings = outputs.last_hidden_state.mean(dim = 1) # Performing pooling i.e. averaging the last hidden state embeddings over the sequence length to get fixed size embeddings\n",
    "        \n",
    "        classification_logits = self.text_classification(embeddings) # Passing the shared embeddings to classification head to get classification output probability\n",
    "        sentiment_logits =  self.sentiment(embeddings) # Passing the shared embeddings to sentiment head to get sentiment output probability\n",
    "\n",
    "        return classification_logits, sentiment_logits # get both task's outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of sentences with variable length to check if we get the embeddings of fixed-size and get example outputs of both the tasks\n",
    "\n",
    "sentences = ['I love Pizza',\n",
    "            'I went to the zoo and saw a tiger',\n",
    "            'After all, you are my wonderwall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vipulsarode/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Calling out the model\n",
    "sentence_transformer = SentenceTransformer_V2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# giving the list of sentences to the model as an input\n",
    "class_logits, sentiment_logits = sentence_transformer(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output shape of classification head: torch.Size([3, 5])\n",
      "The output shape of sentiment head: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# CHecking the Outputs shape for both the task outputs\n",
    "\n",
    "print('The output shape of classification head:', class_logits.shape) # 3 sentences and 5 possible outcomes - for example - happy, sad, angry, fear, disgust\n",
    "print('The output shape of sentiment head:', sentiment_logits.shape) # 3 sentences and 3 possible outcomes - for example -  positive, negative and neutral"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
